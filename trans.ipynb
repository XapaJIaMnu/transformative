{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<s>': 0, 'I': 1, 'LIKE': 2, 'PIE': 3, 'VERY': 4, 'MUCH': 5, '.': 6, 'WE': 7, 'ARE': 8, 'YOUNG': 9, '<unk>': 10, 'Peter': 11}\n",
      "<unk> I Peter ARE ARE <unk> LIKE <unk>\n",
      ". <unk> . . .\n",
      "\n",
      "Loss:  33.54551696777344\n",
      "<unk> I Peter ARE ARE <unk> LIKE <unk>\n",
      ". <unk> . . .\n",
      "\n",
      "Loss:  32.426025390625\n",
      "<unk> I Peter I ARE <unk> LIKE <unk>\n",
      ". <unk> . . .\n",
      "\n",
      "Loss:  31.35788917541504\n",
      "<unk> I Peter I ARE <unk> LIKE <unk>\n",
      ". <unk> . . .\n",
      "\n",
      "Loss:  30.319353103637695\n",
      "<unk> I Peter I ARE <unk> LIKE <unk>\n",
      ". <unk> . . .\n",
      "\n",
      "Loss:  29.283897399902344\n",
      "<unk> I Peter I ARE <unk> LIKE <unk>\n",
      ". <unk> . . .\n",
      "\n",
      "Loss:  28.258575439453125\n",
      "<unk> I Peter I ARE <unk> LIKE <unk>\n",
      ". <unk> PIE . .\n",
      "\n",
      "Loss:  27.24437713623047\n",
      "<unk> I YOUNG I ARE <unk> LIKE <unk>\n",
      ". <unk> PIE . .\n",
      "\n",
      "Loss:  26.23405647277832\n",
      "<unk> I YOUNG I ARE <unk> LIKE <unk>\n",
      ". <unk> PIE . .\n",
      "\n",
      "Loss:  25.224245071411133\n",
      "<unk> I YOUNG I ARE <unk> ARE <unk>\n",
      ". <unk> PIE . .\n",
      "\n",
      "Loss:  24.27664566040039\n",
      "<unk> I YOUNG I ARE <unk> ARE .\n",
      ". <unk> PIE . .\n",
      "\n",
      "Loss:  23.41105079650879\n",
      "<unk> I Peter I ARE . ARE .\n",
      ". <unk> PIE . .\n",
      "\n",
      "Loss:  22.603837966918945\n",
      "<unk> I Peter I ARE . ARE .\n",
      ". <unk> PIE . .\n",
      "\n",
      "Loss:  21.82826042175293\n",
      ". I Peter I ARE . ARE .\n",
      ". <unk> PIE . .\n",
      "\n",
      "Loss:  21.137279510498047\n",
      ". I Peter ARE ARE . ARE .\n",
      ". <unk> PIE PIE Peter\n",
      "\n",
      "Loss:  20.48793601989746\n",
      ". I Peter ARE ARE . ARE .\n",
      ". <unk> PIE PIE Peter\n",
      "\n",
      "Loss:  19.830720901489258\n",
      ". I Peter ARE ARE . ARE .\n",
      ". <unk> PIE PIE Peter\n",
      "\n",
      "Loss:  19.15666961669922\n",
      ". I Peter ARE ARE . ARE .\n",
      ". <unk> PIE . Peter\n",
      "\n",
      "Loss:  18.475725173950195\n",
      ". I Peter ARE ARE . ARE .\n",
      ". <unk> PIE . Peter\n",
      "\n",
      "Loss:  17.79191017150879\n",
      ". I Peter ARE Peter . ARE .\n",
      ". <unk> PIE . Peter\n",
      "\n",
      "Loss:  17.10948371887207\n",
      ". I Peter ARE Peter . ARE .\n",
      ". <unk> PIE . Peter\n",
      "\n",
      "Loss:  16.432008743286133\n",
      ". I Peter ARE Peter . ARE .\n",
      ". <unk> PIE . Peter\n",
      "\n",
      "Loss:  15.762813568115234\n",
      ". I Peter ARE Peter . ARE .\n",
      ". <unk> PIE . Peter\n",
      "\n",
      "Loss:  15.116287231445312\n",
      ". I Peter ARE Peter . LIKE .\n",
      ". <unk> YOUNG . Peter\n",
      "\n",
      "Loss:  14.485390663146973\n",
      ". I Peter ARE Peter . LIKE .\n",
      ". <unk> YOUNG . Peter\n",
      "\n",
      "Loss:  13.858707427978516\n",
      ". I Peter I Peter . LIKE .\n",
      ". MUCH YOUNG . Peter\n",
      "\n",
      "Loss:  13.223649024963379\n",
      ". I Peter I Peter . LIKE .\n",
      ". MUCH YOUNG . Peter\n",
      "\n",
      "Loss:  12.574312210083008\n",
      ". I Peter I Peter . LIKE .\n",
      ". MUCH YOUNG . YOUNG\n",
      "\n",
      "Loss:  11.917160034179688\n",
      ". I YOUNG I VERY . LIKE .\n",
      ". MUCH YOUNG . YOUNG\n",
      "\n",
      "Loss:  11.264644622802734\n",
      ". I YOUNG I VERY . LIKE .\n",
      ". <unk> PIE YOUNG YOUNG\n",
      "\n",
      "Loss:  10.629878044128418\n",
      ". I YOUNG I VERY . I .\n",
      ". <unk> PIE YOUNG Peter\n",
      "\n",
      "Loss:  10.024799346923828\n",
      "<unk> I YOUNG I VERY . I .\n",
      "Peter WE PIE YOUNG Peter\n",
      "\n",
      "Loss:  9.421151161193848\n",
      "<unk> I YOUNG I VERY . I .\n",
      "Peter WE PIE YOUNG Peter\n",
      "\n",
      "Loss:  8.787034034729004\n",
      "<unk> I YOUNG I VERY . I .\n",
      "Peter WE YOUNG YOUNG Peter\n",
      "\n",
      "Loss:  8.366065979003906\n",
      "<unk> I Peter I VERY . I .\n",
      "Peter WE YOUNG YOUNG Peter\n",
      "\n",
      "Loss:  7.948951721191406\n",
      "<unk> I Peter I VERY . PIE .\n",
      "Peter WE YOUNG YOUNG Peter\n",
      "\n",
      "Loss:  7.536773204803467\n",
      "<unk> I Peter I VERY . PIE .\n",
      ". WE YOUNG YOUNG Peter\n",
      "\n",
      "Loss:  7.1432719230651855\n",
      "<unk> I Peter I VERY <unk> PIE .\n",
      ". WE PIE YOUNG Peter\n",
      "\n",
      "Loss:  6.7702836990356445\n",
      "<unk> I Peter I VERY <unk> PIE .\n",
      ". WE PIE . <s>\n",
      "\n",
      "Loss:  6.423799514770508\n",
      "<unk> I Peter I VERY <unk> PIE .\n",
      ". WE PIE . <s>\n",
      "\n",
      "Loss:  6.090141773223877\n",
      "<unk> I Peter I VERY <unk> PIE .\n",
      "<s> WE PIE . <s>\n",
      "\n",
      "Loss:  5.7632904052734375\n",
      "<unk> I Peter I VERY <unk> PIE .\n",
      "<s> WE PIE . <s>\n",
      "\n",
      "Loss:  5.437606334686279\n",
      "<unk> I Peter I VERY <unk> PIE .\n",
      "<s> WE PIE . <s>\n",
      "\n",
      "Loss:  5.105894088745117\n",
      "<unk> I Peter I VERY . PIE .\n",
      "<s> WE PIE . <s>\n",
      "\n",
      "Loss:  4.769418239593506\n",
      "<unk> I Peter I VERY . PIE .\n",
      "<s> WE PIE . <s>\n",
      "\n",
      "Loss:  4.425194263458252\n",
      "<unk> I Peter I VERY . PIE .\n",
      "<s> WE PIE . <s>\n",
      "\n",
      "Loss:  4.086491584777832\n",
      "<unk> I LIKE I VERY . PIE .\n",
      "<s> WE PIE . <s>\n",
      "\n",
      "Loss:  3.7747244834899902\n",
      "<unk> I LIKE I VERY . PIE .\n",
      "<s> WE PIE . <s>\n",
      "\n",
      "Loss:  3.4986186027526855\n",
      "<unk> I LIKE I VERY . PIE .\n",
      "<s> WE PIE . <s>\n",
      "\n",
      "Loss:  3.253063201904297\n",
      "<unk> I LIKE I VERY . PIE .\n",
      "<s> WE PIE . <s>\n",
      "\n",
      "Loss:  3.029665231704712\n",
      "<unk> I LIKE I VERY . PIE .\n",
      "<s> WE PIE . <s>\n",
      "\n",
      "Loss:  2.827728271484375\n",
      "MUCH I LIKE I VERY MUCH PIE .\n",
      "<s> WE PIE YOUNG <s>\n",
      "\n",
      "Loss:  2.6506972312927246\n",
      "MUCH I LIKE I VERY MUCH PIE .\n",
      "<s> WE PIE YOUNG <s>\n",
      "\n",
      "Loss:  2.495269775390625\n",
      "MUCH I LIKE I VERY MUCH PIE .\n",
      "<s> WE PIE YOUNG <s>\n",
      "\n",
      "Loss:  2.35837459564209\n",
      "MUCH I LIKE I VERY MUCH PIE <s>\n",
      "<s> WE PIE YOUNG <s>\n",
      "\n",
      "Loss:  2.2314512729644775\n",
      "MUCH I LIKE I VERY MUCH PIE <s>\n",
      "<s> WE PIE YOUNG .\n",
      "\n",
      "Loss:  2.1129841804504395\n",
      "MUCH I LIKE I VERY MUCH PIE <s>\n",
      "<s> WE PIE YOUNG .\n",
      "\n",
      "Loss:  1.995268702507019\n",
      "MUCH I LIKE I VERY <s> PIE <s>\n",
      "<s> WE PIE YOUNG .\n",
      "\n",
      "Loss:  1.8726518154144287\n",
      "MUCH I LIKE I VERY <s> PIE <s>\n",
      "<s> WE PIE YOUNG .\n",
      "\n",
      "Loss:  1.7462544441223145\n",
      "MUCH I LIKE I VERY <s> PIE <s>\n",
      "<s> WE YOUNG YOUNG .\n",
      "\n",
      "Loss:  1.6174906492233276\n",
      "MUCH I LIKE I VERY <s> PIE <s>\n",
      "<s> WE YOUNG YOUNG .\n",
      "\n",
      "Loss:  1.4872792959213257\n",
      "MUCH I LIKE I VERY <s> PIE <s>\n",
      "<s> WE YOUNG YOUNG .\n",
      "\n",
      "Loss:  1.356993556022644\n",
      "MUCH I LIKE I VERY <s> PIE <s>\n",
      "<s> WE YOUNG YOUNG .\n",
      "\n",
      "Loss:  1.2283906936645508\n",
      "MUCH I LIKE I VERY <s> PIE <s>\n",
      "<s> WE YOUNG . .\n",
      "\n",
      "Loss:  1.1048109531402588\n",
      "MUCH I LIKE I VERY <s> PIE <s>\n",
      "<s> WE YOUNG . .\n",
      "\n",
      "Loss:  0.9914891123771667\n",
      "MUCH I LIKE PIE VERY <s> PIE <s>\n",
      "<s> WE YOUNG . .\n",
      "\n",
      "Loss:  0.8943368196487427\n",
      "MUCH I LIKE PIE VERY <s> PIE <s>\n",
      "<s> WE YOUNG . .\n",
      "\n",
      "Loss:  0.8181390762329102\n",
      "MUCH I LIKE PIE VERY <s> PIE <s>\n",
      "<s> WE YOUNG . .\n",
      "\n",
      "Loss:  0.7635269165039062\n",
      "MUCH PIE LIKE PIE VERY <s> PIE .\n",
      "<s> WE YOUNG . .\n",
      "\n",
      "Loss:  0.7253732085227966\n",
      "MUCH PIE LIKE PIE VERY <s> PIE .\n",
      "<s> WE YOUNG . .\n",
      "\n",
      "Loss:  0.6937665343284607\n",
      "MUCH PIE LIKE PIE VERY <s> PIE .\n",
      "<s> WE YOUNG . .\n",
      "\n",
      "Loss:  0.6619794368743896\n",
      "MUCH PIE LIKE PIE VERY <s> PIE .\n",
      "<s> WE YOUNG . .\n",
      "\n",
      "Loss:  0.6265568137168884\n",
      "MUCH PIE LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE . .\n",
      "\n",
      "Loss:  0.5874940752983093\n",
      "MUCH PIE LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.5465936660766602\n",
      "MUCH PIE LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.5086297392845154\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.4759233891963959\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.45139262080192566\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.4359496533870697\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.4285045266151428\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.42626145482063293\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.4264152944087982\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.4256294369697571\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.42230841517448425\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.4166816174983978\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.40883511304855347\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.39983564615249634\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.39097368717193604\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.38372474908828735\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.37865036725997925\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3753879964351654\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.37332433462142944\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3715899586677551\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3692780137062073\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.36633867025375366\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.36244627833366394\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3579576909542084\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.35357266664505005\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3498896360397339\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.34696266055107117\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3448454439640045\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.34337499737739563\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3422529399394989\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3411562740802765\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3398880362510681\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3384062647819519\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.33662036061286926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3346764147281647\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.33279016613960266\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.33109918236732483\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3296831250190735\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3285157084465027\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3276081085205078\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.32673344016075134\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.32578346133232117\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.32470420002937317\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.32349032163619995\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3222416341304779\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3209531009197235\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3197701871395111\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.31867292523384094\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3176581561565399\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.31671497225761414\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3158766031265259\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3150353729724884\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3141978085041046\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3133339285850525\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3124561011791229\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3116260766983032\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3108026683330536\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.30999094247817993\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.309294730424881\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.30863210558891296\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.30795663595199585\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3073086440563202\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3066864013671875\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3060491383075714\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.30539435148239136\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.30480316281318665\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3042190968990326\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3036235272884369\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3030472993850708\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3025147020816803\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.301965594291687\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.30141115188598633\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.3008659780025482\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.30030953884124756\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2997637093067169\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2992264926433563\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2986873686313629\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2981926202774048\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2976776361465454\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2971583604812622\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2966488301753998\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2961501479148865\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2956412136554718\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2951458692550659\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2946659028530121\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.29417625069618225\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2937168478965759\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.29325345158576965\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.29277604818344116\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.29230746626853943\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2918534576892853\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.29139643907546997\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.29094335436820984\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2905053496360779\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.29006674885749817\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2896513342857361\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.28923094272613525\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2887926399707794\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.288376122713089\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.28796714544296265\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2875332534313202\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2871311902999878\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2867528200149536\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.28634563088417053\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.28594592213630676\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2855590581893921\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2851669192314148\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2848316431045532\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.28447225689888\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.28408581018447876\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.283732533454895\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2833874821662903\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2830272614955902\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2826473116874695\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.28230759501457214\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2819744348526001\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2816031277179718\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.28123193979263306\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2808968424797058\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2805410623550415\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2801874876022339\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.27984803915023804\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.27949994802474976\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2791604697704315\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2788130044937134\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.27847155928611755\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2781390845775604\n",
      "MUCH I LIKE PIE VERY <s> PIE .\n",
      "<s> WE ARE YOUNG .\n",
      "\n",
      "Loss:  0.2777947783470154\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from math import sin, cos\n",
    "from typing import List, Dict\n",
    "\n",
    "SENTENCE = \"<s> I LIKE PIE VERY MUCH PIE .\"\n",
    "SENTENCE2 = \"<s> WE ARE YOUNG .\"\n",
    "DIM_EMB = 512\n",
    "torch.manual_seed(7)\n",
    "\n",
    "vocab = dict()\n",
    "i = 0\n",
    "for token in SENTENCE.split():\n",
    "    if token not in vocab:\n",
    "        vocab[token] = i\n",
    "        i += 1\n",
    "\n",
    "for token in SENTENCE2.split():\n",
    "    if token not in vocab:\n",
    "        vocab[token] = i\n",
    "        i += 1\n",
    "        \n",
    "vocab[\"<unk>\"] = i\n",
    "vocab[\"Peter\"] = i + 1\n",
    "\n",
    "print(vocab)\n",
    "\n",
    "inv_vocab = dict()\n",
    "for word in vocab:\n",
    "    inv_vocab[vocab[word]] = word\n",
    "\n",
    "DICT_SIZE = len(vocab)\n",
    "\n",
    "def getBatch(sents: List[str], vocab: Dict[str, int]) -> torch.Tensor:\n",
    "    #Get max sentence length\n",
    "    DICT_SIZE = len(vocab)\n",
    "    maxLen = 0\n",
    "    for sent in sents:\n",
    "        maxLen = max(maxLen, len(sent.split()))\n",
    "    oneHotBatch = np.zeros((len(sents), maxLen, DICT_SIZE), dtype=float)\n",
    "    for i in range(len(sents)):\n",
    "        curr_sent = sents[i].split()\n",
    "        for j in range(len(curr_sent)):\n",
    "            word = curr_sent[j]\n",
    "            oneHotBatch[i][j][vocab[word]] = 1\n",
    "    return torch.as_tensor(oneHotBatch, dtype=torch.float32)\n",
    "\n",
    "batch_tst = getBatch([SENTENCE, SENTENCE2], vocab)\n",
    "\n",
    "#oneHotSent = np.zeros((len(SENTENCE.split()), DICT_SIZE), dtype=float)\n",
    "\n",
    "#for i in range(len(SENTENCE.split())):\n",
    "#    word = SENTENCE.split()[i]\n",
    "#    oneHotSent[i][vocab[word]] = 1\n",
    "\n",
    "#oneHotTorch = torch.as_tensor(oneHotSent, dtype=torch.float32)\n",
    "    \n",
    "class FUCKYOU(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, batch_size):\n",
    "        super().__init__()\n",
    "        self.DICT_SIZE = vocab_size\n",
    "        self.batch_size = batch_size #@TODO CHANGE\n",
    "        self.transformerHeadConcat = 64 #@TODO CHANGE\n",
    "        \n",
    "        Wq_skeleton = torch.tensor(np.zeros((DIM_EMB, 64), dtype=float), dtype=torch.float32,).normal_(0, 1)\n",
    "        self.Wq = torch.nn.Parameter(Wq_skeleton, requires_grad=True)\n",
    "\n",
    "        Wk_skeleton = torch.tensor(np.zeros((DIM_EMB, 64), dtype=float), dtype=torch.float32,).normal_(0, 1)\n",
    "        self.Wk = torch.nn.Parameter(Wk_skeleton, requires_grad=True)\n",
    "\n",
    "        Wv_skeleton = torch.tensor(np.zeros((DIM_EMB, 64), dtype=float), dtype=torch.float32,).normal_(0, 1)\n",
    "        self.Wv = torch.nn.Parameter(Wv_skeleton, requires_grad=True)\n",
    "        \n",
    "        Wo_skeleton = torch.tensor(np.zeros((self.transformerHeadConcat, DIM_EMB), dtype=float), dtype=torch.float32,).normal_(0, 1)\n",
    "        self.Wo = torch.nn.Parameter(Wo_skeleton, requires_grad=True)\n",
    "        \n",
    "        #Embeddings!\n",
    "        We_skeleton = torch.tensor(np.zeros((DICT_SIZE, DIM_EMB), dtype=float), dtype=torch.float32,).normal_(0, 1)\n",
    "        self.We = torch.nn.Parameter(We_skeleton, requires_grad=True)\n",
    "        \n",
    "        Wff_skeleton = torch.tensor(np.zeros((DIM_EMB, DIM_EMB), dtype=float), dtype=torch.float32,).normal_(0, 1)\n",
    "        self.Wff = torch.nn.Parameter(Wff_skeleton, requires_grad=True)\n",
    "        Bff_skeleton = torch.tensor(np.zeros((DIM_EMB), dtype=float), dtype=torch.float32,).normal_(0, 1)\n",
    "        self.Bff = torch.nn.Parameter(Bff_skeleton, requires_grad=True)\n",
    "        \n",
    "        Wproj_skeleton = torch.tensor(np.zeros((DIM_EMB, DICT_SIZE), dtype=float), dtype=torch.float32,).normal_(0, 1)\n",
    "        self.Wproj = torch.nn.Parameter(Wproj_skeleton, requires_grad=True)\n",
    "        Bproj_skeleton = torch.tensor(np.zeros((DICT_SIZE), dtype=float), dtype=torch.float32,).normal_(0, 1)\n",
    "        self.Bproj = torch.nn.Parameter(Bproj_skeleton, requires_grad=True)\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(self.parameters(), 5)\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr = 0.0001)\n",
    "        \n",
    "    \n",
    "    #DATA PREPARATION DONE\n",
    "\n",
    "    # Create self attention\n",
    "    # also need to add a mask here\n",
    "    # @TODO Add a Bias to all Wsz\n",
    "    def add_transformer_head_with_mask(self, DIM_EMB, Batch, mask):\n",
    "        Q = Batch.matmul(self.Wq)\n",
    "        V = Batch.matmul(self.Wv)\n",
    "        K = Batch.matmul(self.Wk)\n",
    "\n",
    "        tmp1 = Q.matmul(K.permute(0, 2, 1))\n",
    "        #tmp1 = torch.t(K).matmul(Q)\n",
    "\n",
    "        tmp = tmp1/(64**(1/2))\n",
    "        #@TODO this might be wrong for dim=-1\n",
    "        softM = torch.nn.Softmax(dim=-1)\n",
    "        tmp = tmp.masked_fill(mask == 0, -1e9)\n",
    "        #print(\"AFTER MASK\", tmp)\n",
    "        a = softM(tmp)\n",
    "        #print(\"AFTER SOFTMAX\", a)\n",
    "        z = a.matmul(V)\n",
    "        #print(\"After Z*V\", z)\n",
    "        return z\n",
    "\n",
    "    # @TODO add a bias to Wo\n",
    "    def addLinearProj(self, concatTransHead, DIM_EMB):\n",
    "        '''Already concatenataed all heads'''\n",
    "\n",
    "        return concatTransHead.matmul(self.Wo)\n",
    "\n",
    "    #Normalize\n",
    "    def layerNorm(self, mat):\n",
    "        #@TODO there should be a square root here somewhere\n",
    "        return (mat - mat.mean(dim=1, keepdim=True)) / (mat.std(dim=1, keepdim=True))\n",
    "\n",
    "    EPOCHS=10\n",
    "    def fwd(self, oneHotTorch: torch.Tensor):\n",
    "        \n",
    "        #Positional embeddings here\n",
    "        Batch = oneHotTorch.matmul(self.We)\n",
    "        Pos_emb = np.zeros((Batch.shape[1], Batch.shape[2]), dtype=float)\n",
    "        for p in range(len(SENTENCE.split())):\n",
    "            for i in range(DIM_EMB//2):\n",
    "                val = p/(10000**(2*i/DIM_EMB))\n",
    "                Pos_emb[p][2*i] = sin(val)\n",
    "                Pos_emb[p][2*i + 1] = cos(val)\n",
    "\n",
    "        Pos_emb_var = torch.nn.Parameter(torch.tensor(Pos_emb, dtype=torch.float32), requires_grad=False)\n",
    "\n",
    "        Batch = Batch*(DIM_EMB**(1/2))\n",
    "        \n",
    "\n",
    "        Batch = Batch + Pos_emb_var\n",
    "        #Mask the batch post pos_emb\n",
    "        mask1 = torch.sum(oneHotTorch, dim=2) > 0\n",
    "        mask1 = mask1.reshape(2,8,1).float()\n",
    "\n",
    "        Batch = Batch*mask1\n",
    "\n",
    "        #Create MASK HERE\n",
    "        #\n",
    "        mask = np.triu(np.ones((len(SENTENCE.split()), len(SENTENCE.split()))), k=1)\n",
    "        mask = torch.from_numpy(mask) == 0\n",
    "\n",
    "        transformer_head = self.add_transformer_head_with_mask(DIM_EMB, Batch, mask)\n",
    "        postAttention = self.addLinearProj(transformer_head, DIM_EMB)\n",
    "\n",
    "        # Add residual connection to the embeddings\n",
    "        postAttention = postAttention + Batch\n",
    "        #print(postAttention)\n",
    "\n",
    "        normalizedPostAttention = self.layerNorm(postAttention)\n",
    "        #print(normalizedPostAttention)\n",
    "        # @TODO no dropout\n",
    "        # Take the output of the attention and do a one layer FF that outputs size of\n",
    "        activation = torch.nn.ReLU()\n",
    "        postFF = activation(normalizedPostAttention.matmul(self.Wff) + self.Bff)\n",
    "\n",
    "        #Residual\n",
    "        preSoftmaxProj = self.layerNorm(postFF + normalizedPostAttention)\n",
    "\n",
    "        linearLay = preSoftmaxProj.matmul(self.Wproj) + self.Bproj\n",
    "        return linearLay\n",
    "\n",
    "    #@TODO\n",
    "    def getOneHot(self, truth):\n",
    "        ret = torch.Tensor(self.batch_size).long() \n",
    "\n",
    "model = FUCKYOU(DICT_SIZE, len(SENTENCE.split()))\n",
    "EPOCHS=200\n",
    "\n",
    "def printSent(softmaxd, vocab, batch_onehot):\n",
    "    words = [[]]\n",
    "    for j in range(len(softmaxd)):\n",
    "        words.append([])\n",
    "        for i in range(len(softmaxd[j])):\n",
    "            _, idx = torch.max(softmaxd[j][i], 0)\n",
    "            hasWord, _ = torch.max(batch_onehot[j][i], 0)\n",
    "            if hasWord == 1:\n",
    "                words[j].append(vocab[int(idx)])\n",
    "    for arr in words:\n",
    "        print(\" \".join(arr))\n",
    "    \n",
    "def getTruth(oneHotSent):\n",
    "    truth = []\n",
    "    for j in range(len(oneHotSent)):\n",
    "        truth.append([])\n",
    "        for i in range(len(oneHotSent[j])):\n",
    "            _, idx = torch.max(oneHotSent[j][i], 0)\n",
    "            truth[j].append(idx)\n",
    "    return torch.Tensor(truth).long()\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    model.optimizer.zero_grad()\n",
    "    fwd = model.fwd(batch_tst)\n",
    "    printSent(fwd, inv_vocab, batch_tst)\n",
    "    truth = getTruth(batch_tst)\n",
    "    loss = torch.nn.functional.cross_entropy(fwd.permute(0, 2, 1), truth, size_average = True, ignore_index=11)\n",
    "    print(\"Loss: \", loss.item())\n",
    "    loss.backward()\n",
    "    model.optimizer.step()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
